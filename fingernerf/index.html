<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>Improving 3D Finger Traits Recognition via Generalizable Neural Rendering</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="Improving 3D Finger Traits Recognition via Generalizable Neural Rendering" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Improving 3D Finger Traits Recognition via Generalizable Neural Rendering</h1>
            <div class="nerf_subheader_v2">IJCV 2024</div>
            <div class="nerf_subheader_v2">
                <div>
                    <a href="" target="_blank" class="nerf_authors_v2">Hongbin Xu<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Junduan Huang<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Yuer Ma<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Zifeng Li<span
                            class="text-span_nerf"></span></a><sup> 1</sup>
                    <a href="" target="_blank" class="nerf_authors_v2">Wenxiong Kang<span
                        class="text-span_nerf"></span></a><sup> 1*</sup>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>South China University of Technology</h1>
                    <!-- <h1 class="nerf_affiliation_v2"><sup>1* </sup>School of Automation Science and Engineering, South China University of Technology,<br>
                        Wushan Road, Guangzhou, 510641, Guangdong.</h1> -->
                </div>

                <div class="external-link">
                    <a class="btn" href="https://arxiv.org/abs/2410.09582" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/Paper_high_res.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn btn-large btn-light" href="" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>

            </div>
        </div>

    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                3D biometric techniques on finger traits have become a new trend and have demonstrated a powerful ability for recognition and anti-counterfeiting. 
                Existing methods follow an explicit 3D pipeline that reconstructs the models first and then extracts features from 3D models.
                However, these explicit 3D methods suffer from the following problems: 1) Inevitable information dropping during 3D reconstruction; 2) Tight coupling between specific hardware and algorithm for 3D reconstruction.
                It leads us to a question: Is it indispensable to reconstruct 3D information explicitly in recognition  tasks?
                Hence, we consider this problem in an implicit manner, leaving the nerve-wracking 3D reconstruction problem for learnable neural networks with the help of neural radiance fields (NeRFs).
                We propose FingerNeRF, a novel generalizable NeRF for 3D finger biometrics.
                To handle the shape-radiance ambiguity problem that may result in incorrect 3D geometry, we aim to involve extra geometric priors based on the correspondence of binary finger traits like fingerprints or finger veins.
                First, we propose a novel Trait Guided Transformer (TGT) module to enhance the feature correspondence with the guidance of finger traits.
                Second, we involve extra geometric constraints on the volume rendering loss with the proposed Depth Distillation Loss and Trait Guided Rendering Loss.
                To evaluate the performance of the proposed method on different modalities, we collect two new datasets: SCUT-Finger-3D with finger images and SCUT-FingerVein-3D with finger vein images.
                Moreover, we also utilize the UNSW-3D dataset with fingerprint images for evaluation.
                In experiments, our FingerNeRF can achieve 4.37% EER on SCUT-Finger-3D dataset, 8.12% EER on SCUT-FingerVein-3D dataset, and 2.90% EER on UNSW-3D dataset, showing the superiority of the proposed implicit method in 3D finger biometrics.
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div>
    </div>


    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">NeRF-based Generated Results</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">A dragon-cat hybrid <br>&nbsp</p>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/exp_30.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="1_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Albert Einstein with grey suit is riding a bicycle</p>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/Einstein.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="3_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Mini Paris, highly detailed, <br>8K, HD</p>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/miniParis.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="2_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D model of mini China town, highly detailed, 8K, HD, blender 3d</p>
                <video class="video" id="0" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/ChinaTown.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="0_merge"></canvas>
            </div>
        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="nerf-based-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">DMTet-based Generated Results</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">A boy in mohawk hairstyle, head only, 4K, HD, raw</p>
                <video class="video" id="10" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/2023_10_08/aboyinmohawkhairstyle_appearance.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="10_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Fire-breathing Phoenix, mythical bird, engulfed in flames, <br>rebirth and renewal, 3D render, 8K, HD</p>
                <video class="video" id="11" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/Phoenix7_appearance3.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="11_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A bulldog wearing a black pirate hat, highly detailed</p>
                <video class="video" id="12" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/dog_appearance8.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="12_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D model of mini China town, highly detailed, 8K, HD, blender 3d</p>
                <video class="video" id="13" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/2023_10_05/ChinaTown0_appearance.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="13_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-1">
            <a class="mybtn" href="dmtet-based-gallery_0.html" role="button">
            More Results </a>
        </div>
    </div> -->


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/framework_2.png">
            <p>
                
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Qualitative Comparison</h2>
        <div class="grid-container-1">
            <img src="assets/images/comparison_with_mvsnerf.png">
            <p>
                we provide qualitative comparison
                results between the proposed FingerNeRF and
                the representative method of generalizable NeRF,
                MVSNeRF. The rendered images and depth
                maps on a continuous sequence of camera tra-
                jectories are shown in the figure. Due to the
                shape-radiance ambiguity, we can find that the
                rendered depth map of MVSNeRF tends to be
                incorrect. The depth values on the edge area and
                the center area of finger have no clear difference.
                It does not make sense, considering that the shape
                of finger is similar to an elliptic cylinder. Whereas
                our method can render both the reasonable depth
                maps and images as shown in the figure.
            </p>
        </div>
    </div>

<!-- <div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<div class="bibtex">
    <pre><code>@article{sweetdreamer,
author    = {Weiyu Li and Rui Chen and Xuelin Chen and Ping Tan},
title     = {Improving 3D Finger Traits Recognition via Generalizable Neural Rendering},
journal   = {arxiv:2310.02596},
year      = {2023},
}</code></pre>
</div>
</div> -->

</body>
<footer>
    This project page is inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>, © Hongbin Xu. All rights reserved.
</footer>

</html>
